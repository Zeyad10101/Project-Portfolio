{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c379ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect relevant content through the Reddit API.\n",
    "import json\n",
    "import praw\n",
    "# PRAW documentation:\n",
    "#  https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a49ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: enter proper access credential in the config-file;\n",
    "# follow instructions in reddit_credentials_verify.ipynb\n",
    "import config_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665de04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish an API connection and verify read-only access\n",
    "reddit = praw.Reddit(user_agent=f\"Exploration script by /u/{config_reddit.user_name}\",\n",
    "                     client_id=config_reddit.app_id,\n",
    "                     client_secret=config_reddit.app_secret)\n",
    "reddit.read_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dc01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a subreddit of interest\n",
    "# MODIFY this to what you prefer to analyze\n",
    "#\n",
    "# Example (take the string from the ending-part of the subreddit URL):\n",
    "#  https://www.reddit.com/r/ebikes/\n",
    "query_subreddit = 'ebikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2844a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how many top-\"hot\" posts to query\n",
    "nposts = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fe0510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect ids of the top posts within the chosen subreddit\n",
    "post_ids = []\n",
    "subreddit = reddit.subreddit(query_subreddit)\n",
    "for p in subreddit.hot(limit = nposts):\n",
    "    post_ids.append(p.id)\n",
    "# check how many posts (submissions) were collected\n",
    "len(post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9039701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike friendly neighborhoods start at the local level. You can make a difference.\n",
      "1.\tTransportation infrastructure policy is largely done at the local level. \n",
      "2.\tA shockingly small number of people are actually involved in making this policy. \n",
      "3.\tIndividual Advocates can have a huge impact at the city level. \n",
      "\n",
      "Bottom line: Anyone can make a difference! \n",
      "\n",
      "Even if you can't afford to catch a local politicians ear via donation... or if you don't have the free time to show up at a city hall meeting... you can still be an educator/advocate on social media. \n",
      "\n",
      "**Education**\n",
      "\n",
      "Youtube:\n",
      "\n",
      "* [Why City Design is Important \\(and Why I Hate Houston\\) by Not Just Bikes](https://www.youtube.com/watch?v=uxykI30fS54)\n",
      "\n",
      "* [The Ugly, Dangerous, and Inefficient Stroads found all over the US & Canada by Not Just Bikes](https://www.youtube.com/watch?v=ORzNZUeUHAM)\n",
      "\n",
      "* [Bike lanes are not enough by City Beautiful](https://www.youtube.com/watch?v=p36skNda3KE)\n",
      "\n",
      "\n",
      "\n",
      "Tiktok:\n",
      "\n",
      "* [Phil Sustainability & Enviro](https://www.tiktok.com/t/ZTR8DKkeW/)\n",
      "\n",
      "* [TalkingCities](https://www.tiktok.com/@talkingcities)\n",
      "\n",
      "Web:\n",
      "\n",
      "* [Strong Towns](https://www.strongtowns.org/bike)\n",
      "\n",
      "**Get involved:**\n",
      "\n",
      "* [Strong Towns on Facebook](https://www.facebook.com/strongtowns) \n",
      "\n",
      "* [People for Bikes on Facebook](https://www.facebook.com/PeopleForBikes)\n",
      "\n",
      "\n",
      "*Please leave a comment if you have any other resources you'd like to add.*\n"
     ]
    }
   ],
   "source": [
    "# example post details\n",
    "post_details = reddit.submission(id = post_ids[1])\n",
    "print(post_details.title)\n",
    "print(post_details.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56c8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how many top comments to query per post;\n",
    "# NOTE: larger number of comments may dilute the content (irrelevant text)\n",
    "ncomments = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26881fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect post data\n",
    "def collect_post_data(post_id, ncomments, reddit):\n",
    "    psubm = reddit.submission(id = post_id)\n",
    "    pdata = {'id': post_id, 'title': psubm.title, 'text': psubm.selftext}\n",
    "    \n",
    "    # collect first- and second-level comments\n",
    "    pcomm = []\n",
    "    psubcomm = []\n",
    "    psubm.comments.replace_more(limit = ncomments)\n",
    "    for top_comment in psubm.comments:\n",
    "        pcomm.append(top_comment.body)\n",
    "        for lev2_comment in top_comment.replies:\n",
    "            psubcomm.append(lev2_comment.body)\n",
    "    \n",
    "    # assemble the data together\n",
    "    pdata['comments_lev1'] = pcomm\n",
    "    pdata['comments_lev2'] = psubcomm\n",
    "    \n",
    "    return pdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47669ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect information for each post\n",
    "posts_all = [collect_post_data(pid, ncomments, reddit) for pid in post_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1d23c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posts_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kr/1zs240g17nl_9nf02dsqzmwc0000gn/T/ipykernel_77788/2002153932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"raw_post_comment_data.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'posts_all' is not defined"
     ]
    }
   ],
   "source": [
    "# save collected data to json file\n",
    "file_out = f\"raw_post_comment_data.json\"\n",
    "with open(file_out, mode='w') as f:\n",
    "    f.write(json.dumps(posts_all, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557f272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
